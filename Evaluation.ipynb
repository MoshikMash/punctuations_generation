{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd5a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reading_and_preprocessing import DataPreprocessing\n",
    "from model_pipeline import ModelPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb939d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "model was loaded -- name: models/fine_tuned_model_950.p\n",
      "\n",
      "Running Test Evaluation...\n",
      "  Batch    40  of  2,047.    Elapsed: 0:00:08. Total Train Loss: 4.21\n",
      "  Batch    80  of  2,047.    Elapsed: 0:00:16. Total Train Loss: 8.45\n",
      "  Batch   120  of  2,047.    Elapsed: 0:00:24. Total Train Loss: 12.12\n",
      "  Batch   160  of  2,047.    Elapsed: 0:00:32. Total Train Loss: 16.88\n",
      "  Batch   200  of  2,047.    Elapsed: 0:00:40. Total Train Loss: 20.68\n",
      "  Batch   240  of  2,047.    Elapsed: 0:00:48. Total Train Loss: 24.5\n",
      "  Batch   280  of  2,047.    Elapsed: 0:00:55. Total Train Loss: 28.8\n",
      "  Batch   320  of  2,047.    Elapsed: 0:01:03. Total Train Loss: 32.67\n",
      "  Batch   360  of  2,047.    Elapsed: 0:01:10. Total Train Loss: 36.82\n",
      "  Batch   400  of  2,047.    Elapsed: 0:01:19. Total Train Loss: 40.96\n",
      "  Batch   440  of  2,047.    Elapsed: 0:01:27. Total Train Loss: 45.37\n",
      "  Batch   480  of  2,047.    Elapsed: 0:01:35. Total Train Loss: 48.77\n",
      "  Batch   520  of  2,047.    Elapsed: 0:01:43. Total Train Loss: 53.31\n",
      "  Batch   560  of  2,047.    Elapsed: 0:01:52. Total Train Loss: 57.66\n",
      "  Batch   600  of  2,047.    Elapsed: 0:02:01. Total Train Loss: 61.96\n",
      "  Batch   640  of  2,047.    Elapsed: 0:02:09. Total Train Loss: 65.78\n",
      "  Batch   680  of  2,047.    Elapsed: 0:02:17. Total Train Loss: 69.46\n",
      "  Batch   720  of  2,047.    Elapsed: 0:02:25. Total Train Loss: 73.44\n",
      "  Batch   760  of  2,047.    Elapsed: 0:02:33. Total Train Loss: 77.8\n",
      "  Batch   800  of  2,047.    Elapsed: 0:02:41. Total Train Loss: 82.51\n",
      "  Batch   840  of  2,047.    Elapsed: 0:02:49. Total Train Loss: 86.45\n",
      "  Batch   880  of  2,047.    Elapsed: 0:02:56. Total Train Loss: 90.66\n",
      "  Batch   920  of  2,047.    Elapsed: 0:03:04. Total Train Loss: 94.27\n",
      "  Batch   960  of  2,047.    Elapsed: 0:03:12. Total Train Loss: 98.51\n",
      "  Batch 1,000  of  2,047.    Elapsed: 0:03:20. Total Train Loss: 102.18\n",
      "  Batch 1,040  of  2,047.    Elapsed: 0:03:28. Total Train Loss: 105.78\n",
      "  Batch 1,080  of  2,047.    Elapsed: 0:03:35. Total Train Loss: 109.92\n",
      "  Batch 1,120  of  2,047.    Elapsed: 0:03:43. Total Train Loss: 113.94\n",
      "  Batch 1,160  of  2,047.    Elapsed: 0:03:51. Total Train Loss: 118.06\n",
      "  Batch 1,200  of  2,047.    Elapsed: 0:03:59. Total Train Loss: 122.74\n",
      "  Batch 1,240  of  2,047.    Elapsed: 0:04:07. Total Train Loss: 127.47\n",
      "  Batch 1,280  of  2,047.    Elapsed: 0:04:15. Total Train Loss: 130.73\n",
      "  Batch 1,320  of  2,047.    Elapsed: 0:04:23. Total Train Loss: 135.28\n",
      "  Batch 1,360  of  2,047.    Elapsed: 0:04:31. Total Train Loss: 139.94\n",
      "  Batch 1,400  of  2,047.    Elapsed: 0:04:40. Total Train Loss: 144.09\n",
      "  Batch 1,440  of  2,047.    Elapsed: 0:04:47. Total Train Loss: 148.45\n",
      "  Batch 1,480  of  2,047.    Elapsed: 0:04:55. Total Train Loss: 152.82\n",
      "  Batch 1,520  of  2,047.    Elapsed: 0:05:03. Total Train Loss: 157.02\n",
      "  Batch 1,560  of  2,047.    Elapsed: 0:05:10. Total Train Loss: 161.4\n",
      "  Batch 1,600  of  2,047.    Elapsed: 0:05:18. Total Train Loss: 166.18\n",
      "  Batch 1,640  of  2,047.    Elapsed: 0:05:28. Total Train Loss: 170.84\n",
      "  Batch 1,680  of  2,047.    Elapsed: 0:05:36. Total Train Loss: 174.7\n",
      "  Batch 1,720  of  2,047.    Elapsed: 0:05:44. Total Train Loss: 178.8\n",
      "  Batch 1,760  of  2,047.    Elapsed: 0:05:53. Total Train Loss: 182.77\n",
      "  Batch 1,800  of  2,047.    Elapsed: 0:06:01. Total Train Loss: 186.8\n",
      "  Batch 1,840  of  2,047.    Elapsed: 0:06:09. Total Train Loss: 191.11\n",
      "  Batch 1,880  of  2,047.    Elapsed: 0:06:17. Total Train Loss: 195.4\n",
      "  Batch 1,920  of  2,047.    Elapsed: 0:06:25. Total Train Loss: 199.55\n",
      "  Batch 1,960  of  2,047.    Elapsed: 0:06:33. Total Train Loss: 203.57\n",
      "  Batch 2,000  of  2,047.    Elapsed: 0:06:41. Total Train Loss: 207.17\n",
      "  Batch 2,040  of  2,047.    Elapsed: 0:06:49. Total Train Loss: 211.98\n",
      "  Accuracy: 0.96\n",
      "  Test Loss: 0.10\n",
      "  Test took: 0:06:50\n",
      "\n",
      "Test Evaluation complete!\n",
      "test results dataframe was saved -- file name: test_results/test_results_with_scores_950.p\n"
     ]
    }
   ],
   "source": [
    "model_number = 950\n",
    "model_pipeline = ModelPipeline()\n",
    "model_pipeline.load_model(f'models/fine_tuned_model_{model_number}')\n",
    "model_pipeline.load_new_test_data(\n",
    "    'validation_set/c4-iw-validation.tfrecord-00000-of-00001.json.gz.p')\n",
    "model_pipeline.evaluation_with_prediction_scores(f'test_results/test_results_with_scores_{model_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f74c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "model was loaded -- name: models/fine_tuned_model_1000.p\n",
      "\n",
      "Running Test Evaluation...\n",
      "  Batch    40  of  2,047.    Elapsed: 0:00:08. Total Train Loss: 4.32\n",
      "  Batch    80  of  2,047.    Elapsed: 0:00:16. Total Train Loss: 8.5\n",
      "  Batch   120  of  2,047.    Elapsed: 0:00:24. Total Train Loss: 12.17\n",
      "  Batch   160  of  2,047.    Elapsed: 0:00:32. Total Train Loss: 16.85\n",
      "  Batch   200  of  2,047.    Elapsed: 0:00:40. Total Train Loss: 20.63\n",
      "  Batch   240  of  2,047.    Elapsed: 0:00:49. Total Train Loss: 24.44\n",
      "  Batch   280  of  2,047.    Elapsed: 0:00:58. Total Train Loss: 28.68\n",
      "  Batch   320  of  2,047.    Elapsed: 0:01:06. Total Train Loss: 32.53\n",
      "  Batch   360  of  2,047.    Elapsed: 0:01:14. Total Train Loss: 36.69\n",
      "  Batch   400  of  2,047.    Elapsed: 0:01:21. Total Train Loss: 40.84\n",
      "  Batch   440  of  2,047.    Elapsed: 0:01:29. Total Train Loss: 45.26\n",
      "  Batch   480  of  2,047.    Elapsed: 0:01:36. Total Train Loss: 48.7\n",
      "  Batch   520  of  2,047.    Elapsed: 0:01:43. Total Train Loss: 52.97\n",
      "  Batch   560  of  2,047.    Elapsed: 0:01:51. Total Train Loss: 57.31\n",
      "  Batch   600  of  2,047.    Elapsed: 0:02:00. Total Train Loss: 61.43\n",
      "  Batch   640  of  2,047.    Elapsed: 0:02:07. Total Train Loss: 65.24\n",
      "  Batch   680  of  2,047.    Elapsed: 0:02:15. Total Train Loss: 68.88\n",
      "  Batch   720  of  2,047.    Elapsed: 0:02:23. Total Train Loss: 72.86\n",
      "  Batch   760  of  2,047.    Elapsed: 0:02:30. Total Train Loss: 77.11\n",
      "  Batch   800  of  2,047.    Elapsed: 0:02:38. Total Train Loss: 81.78\n",
      "  Batch   840  of  2,047.    Elapsed: 0:02:46. Total Train Loss: 85.68\n",
      "  Batch   880  of  2,047.    Elapsed: 0:02:54. Total Train Loss: 89.83\n",
      "  Batch   920  of  2,047.    Elapsed: 0:03:02. Total Train Loss: 93.47\n",
      "  Batch   960  of  2,047.    Elapsed: 0:03:10. Total Train Loss: 97.69\n",
      "  Batch 1,000  of  2,047.    Elapsed: 0:03:18. Total Train Loss: 101.35\n",
      "  Batch 1,040  of  2,047.    Elapsed: 0:03:25. Total Train Loss: 104.87\n",
      "  Batch 1,080  of  2,047.    Elapsed: 0:03:33. Total Train Loss: 108.99\n",
      "  Batch 1,120  of  2,047.    Elapsed: 0:03:40. Total Train Loss: 113.03\n",
      "  Batch 1,160  of  2,047.    Elapsed: 0:03:48. Total Train Loss: 117.1\n",
      "  Batch 1,200  of  2,047.    Elapsed: 0:03:55. Total Train Loss: 121.78\n",
      "  Batch 1,240  of  2,047.    Elapsed: 0:04:02. Total Train Loss: 126.53\n",
      "  Batch 1,280  of  2,047.    Elapsed: 0:04:10. Total Train Loss: 129.78\n",
      "  Batch 1,320  of  2,047.    Elapsed: 0:04:18. Total Train Loss: 133.97\n",
      "  Batch 1,360  of  2,047.    Elapsed: 0:04:26. Total Train Loss: 138.49\n",
      "  Batch 1,400  of  2,047.    Elapsed: 0:04:34. Total Train Loss: 142.53\n",
      "  Batch 1,440  of  2,047.    Elapsed: 0:04:42. Total Train Loss: 146.87\n",
      "  Batch 1,480  of  2,047.    Elapsed: 0:04:52. Total Train Loss: 151.27\n",
      "  Batch 1,520  of  2,047.    Elapsed: 0:05:00. Total Train Loss: 155.39\n",
      "  Batch 1,560  of  2,047.    Elapsed: 0:05:07. Total Train Loss: 159.9\n",
      "  Batch 1,600  of  2,047.    Elapsed: 0:05:15. Total Train Loss: 164.63\n",
      "  Batch 1,640  of  2,047.    Elapsed: 0:05:22. Total Train Loss: 169.41\n",
      "  Batch 1,680  of  2,047.    Elapsed: 0:05:30. Total Train Loss: 173.27\n",
      "  Batch 1,720  of  2,047.    Elapsed: 0:05:37. Total Train Loss: 177.31\n",
      "  Batch 1,760  of  2,047.    Elapsed: 0:05:46. Total Train Loss: 181.32\n",
      "  Batch 1,800  of  2,047.    Elapsed: 0:05:53. Total Train Loss: 185.34\n",
      "  Batch 1,840  of  2,047.    Elapsed: 0:06:01. Total Train Loss: 189.77\n",
      "  Batch 1,880  of  2,047.    Elapsed: 0:06:08. Total Train Loss: 194.0\n",
      "  Batch 1,920  of  2,047.    Elapsed: 0:06:16. Total Train Loss: 198.03\n",
      "  Batch 1,960  of  2,047.    Elapsed: 0:06:23. Total Train Loss: 202.18\n",
      "  Batch 2,000  of  2,047.    Elapsed: 0:06:31. Total Train Loss: 205.73\n",
      "  Batch 2,040  of  2,047.    Elapsed: 0:06:40. Total Train Loss: 210.42\n",
      "  Accuracy: 0.96\n",
      "  Test Loss: 0.10\n",
      "  Test took: 0:06:41\n",
      "\n",
      "Test Evaluation complete!\n",
      "test results dataframe was saved -- file name: test_results/test_results_with_scores_1000.p\n"
     ]
    }
   ],
   "source": [
    "model_number = 1000\n",
    "model_pipeline = ModelPipeline()\n",
    "model_pipeline.load_model(f'models/fine_tuned_model_{model_number}')\n",
    "model_pipeline.load_new_test_data(\n",
    "    'validation_set/c4-iw-validation.tfrecord-00000-of-00001.json.gz.p')\n",
    "model_pipeline.evaluation_with_prediction_scores(f'test_results/test_results_with_scores_{model_number}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
